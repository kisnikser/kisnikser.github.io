---
title: "HippoTrainer: Gradient-Based Hyperparameter Optimization for PyTorch"
date: 2025-05-06
lastmod: 2025-03-11
tags: ["hyperparameter optimization", "PyTorch", "Optuna"]
author: ["Daniil Dorin", "Igor Ignashin", "Nikita Kiselev", "Andrey Veprikov"]
description:
summary: ""
editPost:
    URL: https://github.com/intsystems/hippotrainer
    Text: GitHub
showToc: true 
showReadingTime: true
---

In this blog-post we present our Python library [HippoTrainer](https://github.com/intsystems/hippotrainer) (or `hippotrainer`) for gradient-based hyperparameter optimization, implementing cutting-edge algorithms that leverage automatic differentiation to efficiently tune hyperparameters.

## Introduction <a name="introduction"></a>

TODO

## Methods

TODO

## Implementation (see our [GitHub](https://github.com/intsystems/hippotrainer) for details)

TODO

## Demo

TODO

## Conclusion

TODO

## References

TODO